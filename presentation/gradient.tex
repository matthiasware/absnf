%------------------------------------------------------------------------
\begin{frame}
	\frametitle{Content}
	\framesubtitle{ABS-Normal Form}
	\begin{columns}[T] % align columns
		\begin{column}{.48\textwidth}
			
			\begin{center}
				{\Huge Gradient}
			\end{center}
			
		\end{column}%
		\hfill%
		\begin{column}{.48\textwidth}
			\color{blue}\rule{\linewidth}{4pt}
			
			\setbeamertemplate{enumerate items}[default]
			\begin{enumerate}
				\item Einführung
				\item Aufgaben
				\item Evaluate
				\item \textbf{Gradient}
				\item Blocksize und Gridsize
				\item Solve
				\item Final Thoughts
			\end{enumerate}
		\end{column}%
	\end{columns}
\end{frame}
%------------------------------------------------------------------------
\begin{frame}
	\frametitle{Aufgabe 2) Gradient}
	\framesubtitle{Aufgabenbeschreibung}
	\setbeamertemplate{enumerate items}[default]
	\begin{flalign*}
		\begin{pmatrix}
		\Delta z \\
		\Delta y
		\end{pmatrix}
		= 
		\begin{pmatrix}
		a \\
		b
		\end{pmatrix}
		+
		\begin{pmatrix}
		Z & L \\
		J & Y 
		\end{pmatrix}
		\times
		\begin{pmatrix}
		\Delta x \\
		|\Delta z |
		\end{pmatrix}
	\end{flalign*}
	Gegeben:
	\begin{flalign*}
		a,b,Z,L,J,Y,m,n,s, \Delta Z
	\end{flalign*}
	Gesucht:
	\begin{flalign*}
		\gamma, \Gamma
	\end{flalign*}
	Wobei:
	\begin{flalign*}
		\gamma &= b + Y \Sigma(I-L\Sigma)^{-1} a \\
		\Gamma &= J + Y \Sigma(I-L\Sigma)^{-1} Z
	\end{flalign*}
	\begin{flalign*}
		\Sigma = Diag(Sign(\Delta z))
	\end{flalign*}	
\end{frame}
%------------------------------------------------------------------------
\begin{frame}
	\frametitle{Aufgabe 2) Gradient}
	\framesubtitle{Interssanter Teil}
	\setbeamertemplate{enumerate items}[default]
	Brauchen:
	\begin{flalign*}
		\Sigma(I-L\Sigma)^{-1}
	\end{flalign*}
	\begin{flalign*}
		\Sigma = Diag(Sign(\Delta z))
	\end{flalign*}
	Fallstricken:
	\begin{itemize}
		\item <2-> Sparse Matrix $\Sigma$
		\item <3-> Inverse $(I-L\Sigma)^{-1}$
	\end{itemize}
	
\end{frame}
%------------------------------------------------------------------------
\begin{frame}
	\frametitle{Aufgabe 2) Gradient}
	\framesubtitle{Beispiel}
	\setbeamertemplate{enumerate items}[default]
	
	Sei:
	\begin{flalign*}
		\Delta z = [-3, 0, 4,  -1]
	\end{flalign*}
	Dann gilt für $I - L\Sigma$:
	\begin{flalign*} 
	I -
	\left(\begin{array}{cccc}
	0 		& 0 	  & 0  & 0 \\
	L_{2,1} & 0 	  & 0  & 0 \\
	L_{3,1} & L_{3,2} & 0  & 0\\
	L_{4,1} & L_{4,2} & L_{4,3} & 0 \\
	\end{array}\right) \times
	\left(\begin{array}{cccc}
	-1 & 0 & 0 & 0 \\
	0 & 0 & 0 & 0 \\
	0 & 0 & 1 & 0 \\
	0 & 0 & 0 & -1 \\
	\end{array}\right)
	= 
	\left(\begin{array}{cccc}
	1 & 0 & 0 & 0 \\
	-L_{2,1} & 1 & 0 & 0 \\
	-L_{3,1} & 0 & 1 & 0 \\
	-L_{4,1} & 0 & 0 & 1 \\
	\end{array}\right)
	\end{flalign*}
	\pause
	Das entspricht den folgenden Operationen:
	\begin{itemize}
		\item Hinzufügen einer Hauptdiagonalen
		\item Skalieren der Spalten von $L$ mit den Vorzeichen von $\Delta z$
	\end{itemize}
	\pause
	Kann als lineare Operation implementiert werden.
	Das Auflösen der unteren Dreiecksmatrix $(I-L\Sigma)^{-1}$ übernimmt CUBLAS.
\end{frame}
%----------------------------------------------------------------------------
\begin{frame}[fragile]
	\frametitle{Aufgabe 1) Gradient}
	\framesubtitle{Implementierung}
	\begin{lstlisting}[language=cpp]
	template <typename T>
	void gradient(T *a, T *b, 
				  T *Z, T *L, 
				  T *J, T *Y,
				  T *dz,
				  T *Tss, T *I, T *K,
				  int m, int n, int s,
				  int gridsize, int blocksize,
				  T *gamma, T *Gamma)
		//  d_Tss = diag(1) - L * diag(sign(dz))
		initTss <<<gridsize, blocksize >>>(d_Tss,d_L, d_dz, s, s*s);
		//  d_I = diag(1) // room for improvement, operations can be merged		
		initIdentity <<<gridsize, blocksize >>> (d_I, s);
		//  d_I = d_Tss * X	
		getTriangularInverse(handle, d_Tss, d_I, s);
		//	d_I = d_I * diag(sign(dz))
		multWithDz <<<gridsize, blocksize >>>(d_I, d_dz, s);
		//	d_K = d_Y * d_I
		cublasDgemm(.,d_Y,.,d_I,d_K,));
		//	d_gamma = d_b
		//  d_Gamma = J
		cudaMemcpy(d_gamma, d_b,.);
		cudaMemcpy(d_Gamma, d_J,.);
		//	d_gamma = d_gamma + K*a
		cublasDgemv(.,d_K,., d_a,., d_gamma,.);
		//  d_Gamma = d_Gamma + K*Z
		cublasDgemm(.,d_K,d_Z,d_Gamma,m));
	}
	\end{lstlisting}
\end{frame}
%------------------------------------------------------------------------

\begin{frame}
	\frametitle{Aufgabe 2) Gradient}
	\framesubtitle{Speicherkomplexität}
	Speicherkomplexität: \\
	\begin{center}
		\begin{tabular}{ c | c | c | c | c | c | c | c | c | c | c | c }
			$a$ & $b$ & $Z$ & $L$ & $J$ & $Y$ & $\Delta z$ & $\gamma$ & $\Gamma$ & $Tss$ & $I$ & $K$\\
			\hline
			$s$ & $m$ & $s*n$ & $s*s$ & $m*n$ & $m*s$ & $s$ & $m$ & $m*n$& $s*s$ & $s*s$ & $m*s$\\
		\end{tabular}
	\end{center}
	Bei $m=n=s$:
	\begin{flalign*}
		8s^2 + 4s \times sizeof(type)
	\end{flalign*}
	\begin{itemize}
		\item $m=n=s=1000:$  0.064 GB
		\item $m=n=s=5000:$ 1.6 GB
		\item $m=n=s=10.000:$ 6.40 GB
	\end{itemize}
\end{frame}
%------------------------------------------------------------------------
\begin{frame}
	\frametitle{Aufgabe 2) Gradient}
	\framesubtitle{Komplexität}
	Komplexität $(m=n=s)$: \\
	\begin{center}
		\begin{tabular}{ l | l}
			Funktion & Komplexität Seriell \\
			\hline
			$initTss()$	& $s^2$\\
			$initIdentity()$& $s^2$ \\
			$getTriangularInverse()$& $s^2$ (backsubstitution)\\
			$multWithDz()$  & $s^2$  \\
			$cublasDgemm()$& $s^3$ \\
			$cublasDgemv()$ & $s^2$ \\
			$cudaMemcpy()$ & $s$ \\
		\end{tabular} 	\\~\\
	\end{center}
	\begin{center}
		Lässt sich alles gut parallelisieren.
	\end{center}
\end{frame}
\setbeamertemplate{navigation symbols}{}
\begin{frame}[plain]
	\makebox[\linewidth]{\includegraphics[width=\paperwidth]{img/grad-single.png}}
\end{frame}
%------------------------------------------------------------------------
\setbeamertemplate{navigation symbols}{}
\begin{frame}[plain]
	\makebox[\linewidth]{\includegraphics[width=\paperwidth]{img/grad-100.png}}
\end{frame}
%------------------------------------------------------------------------